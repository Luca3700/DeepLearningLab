{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSWSrJ-iTazX"
      },
      "source": [
        "# Generating Images with Generative Adversarial Networks (GANs)\n",
        "\n",
        "The purpose of the project is to test the ability of Generative Adversial Networks (GANs) in generating realistic-looking images. \n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset used will be FashionMNIST. It contains low resolution ($28 \\times 28$) grey-scale images representing different kind of clothes. The dataset is available on keras and accessable in $\\texttt{tf.keras.datasets.fashion\\_mnist}$. Note that the pixel values for the images are initially in the interval $[0, 255]$. It is required to normalize them since all of the algorithm we will use require them to be in that format. To be fair, you will find the dataset already normalized, do not modify that part of the code.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "Measuring the quality of newly generated images is a non-trivial task. Indeed, there is no label associated to each image, and thus it is impossible to measure the quality image-by-image. For that reason, common metrics uses statistical consideration on a generated dataset to test how well the network recovered the statistics of the original data. One of the most common is the Fr√©chet Inception Distance (FID). The idea of FID is that in a realistic-looking dataset of images, the statistics of the activation of the last hidden layer in a well-trained classificator should be similar to that of a dataset containing real images. Specifically, regarding FID, the Inception-v3 network is used as a classificator. A real dataset $\\mathbb{D}_r$ and a generated dataset $\\mathbb{D}_g$ are processed by the network, and the activation of the last hidden layer has mean and variance $(\\mu_r, \\Sigma_r)$, $(\\mu_g, \\Sigma_g)$ respectively. Then, FID is computed as:\n",
        "\n",
        "$$\n",
        "    FID(\\mathbb{D}_r, \\mathbb{D}_g) = || \\mu_r - \\mu_g ||^2 + Tr(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r \\ast \\Sigma_g)^{\\frac{1}{2}}) \n",
        "$$\n",
        "\n",
        "A Python implementation of FID can be found in the file $\\texttt{fid.py}$ that you find attached on Virtuale. Its usage is very simple, just generate $10k$ fake images with your GAN, and with the command $\\texttt{fid.get\\_fid(x\\_test, x\\_gen)}$, where $\\texttt{x\\_test}$ is the test set, containing $10k$ real images, you get the value for the FID of your network. Remember that, when passed through that function, $\\texttt{x\\_gen}$ **must** be a dataset of $10k$ images, in the interval $[0, 1]$. The number of $10k$ images is fundamental, since the value of FID strongly depends on the number of input images.\n",
        "\n",
        "## Limitations\n",
        "\n",
        "You are required to implement a vanilla Generative Adversarial Network (GAN), not a variant of it (e.g. PixelGAN, CycleGAN, ... are **not** accepted). The maximum number of parameters is *15 million*, and every pre-trained network can be used as an add-on (the number of parameters for pre-trained network does not count). Clearly, only the training set can be used to train the network, no additional images (Data Augmentation is ok)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aaubgTXbTazn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceos7zgTTazs"
      },
      "source": [
        "The images are normalized in $[0, 1]$. For simplicity, images are padded to have dimension $32 \\times 32$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es5LDnq0Tazv",
        "outputId": "d95bb949-9925-46e8-b750-089cdd0a007d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shape: (60000, 32, 32, 1), Training pixel values: (0.0, 1.0)\n",
            "Test shape: (10000, 32, 32, 1), Test pixel values: (0.0, 1.0)\n"
          ]
        }
      ],
      "source": [
        "# Load the data. Note that the labels y_train and y_test are not loaded since not required.\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and pad the datasets\n",
        "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)))\n",
        "x_train = np.reshape(x_train, x_train.shape + (1, ))\n",
        "x_train = x_train / 255.\n",
        "\n",
        "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)))\n",
        "x_test = np.reshape(x_test, x_test.shape + (1, ))\n",
        "x_test = x_test / 255.\n",
        "\n",
        "print(f\"Training shape: {x_train.shape}, Training pixel values: {x_train.min(), x_train.max()}\")\n",
        "print(f\"Test shape: {x_test.shape}, Test pixel values: {x_test.min(), x_test.max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRRpm4TkTazy"
      },
      "source": [
        "Now, we import the functions for the computation of the FID, and we test that FID(x_train, x_test) is low.\n",
        "\n",
        "_Note: Computing the FID function requires some minutes. Consequently, it is suggested to comment this cell after you tested once, to reduce the execution time of the notebook. To speed-up the process, after a first use, the function will generate a file containing the value of the activations of the test set, so that it does not have to compute it again every time._ \n",
        "\n",
        "**Remember that, when you use the FID function, the first input MUST be the test set, while the second will be the generated images set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5dPZU1oiTaz1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Do not modify this code. This is just for utilities.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# prepare the inception v3 model\n",
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3), weights='imagenet')\n",
        "\n",
        "def get_inception_activations(inps, batch_size=100):\n",
        "    \"\"\"\n",
        "    Compute the activation for the model Inception v3 for a given input 'inps'.\n",
        "\n",
        "    Note: inps is assumed to be normalized in [0, 1].\n",
        "    \"\"\"\n",
        "    n_batches = inps.shape[0] // batch_size\n",
        "\n",
        "    act = np.zeros([inps.shape[0], 2048], dtype=np.float32)\n",
        "    for i in range(n_batches):\n",
        "        # Load a batch of data\n",
        "        inp = inps[i * batch_size:(i + 1) * batch_size]\n",
        "\n",
        "        # Resize each image to match the input shape of Inception v3\n",
        "        inpr = tf.image.resize(inp, (299, 299))\n",
        "\n",
        "        # Resize images in the interval [-1, 1], given that inpr is in [0, 1].\n",
        "        inpr = inpr * 2 - 1 \n",
        "\n",
        "        # Predict the activation\n",
        "        act[i * batch_size:(i + 1) * batch_size] = model.predict(inpr, steps=1)\n",
        "\n",
        "        print(f\"Processed {str((i + 1) * batch_size)} images.\")\n",
        "    return act\n",
        "\n",
        "\n",
        "def get_fid(images1, images2):\n",
        "    \"\"\"\n",
        "    Compute the FID between two sets of images.\n",
        "\n",
        "    Note: it can take several minutes.\n",
        "    \"\"\"\n",
        "    from scipy.linalg import sqrtm\n",
        "\n",
        "    shape = np.shape(images1)[1]\n",
        "    print(\"Computing FID for {} dimensional images\".format(images1.shape))\n",
        "\n",
        "    # Inception v3 requires the input to have 3 channel. If this is not the\n",
        "    # case, just copy the same channel three times.\n",
        "    if images1.shape[-1] == 1:\n",
        "        images1 = np.concatenate([images1, images1, images1], axis=-1)\n",
        "        images2 = np.concatenate([images2, images2, images2], axis=-1)\n",
        "\n",
        "    # activation for true images is always the same: we just compute it once\n",
        "    if os.path.exists(\"act_mu.npy\"):\n",
        "        mu1 = np.load(\"act_mu.npy\")\n",
        "        sigma1 = np.load(\"act_sigma.npy\")\n",
        "    else:\n",
        "        act1 = get_inception_activations(images1)\n",
        "        mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "        np.save(\"act_mu.npy\", mu1)\n",
        "        np.save(\"act_sigma.npy\", sigma1)\n",
        "    print('Done stage 1 of 2')\n",
        "\n",
        "    act2 = get_inception_activations(images2)\n",
        "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "    print('Done stage 2 of 2')\n",
        "\n",
        "    # calculate sum squared difference between means\n",
        "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
        "\n",
        "    # compute sqrt of product between cov\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "    # check and correct imaginary numbers from sqrt\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    # calculate score\n",
        "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    return fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OogQ0Wt3Taz7",
        "outputId": "9a8442b5-06db-45c7-99f8-60fcdb6874d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FID for (10000, 32, 32, 1) dimensional images\n",
            "1/1 [==============================] - 23s 23s/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 10000 images.\n",
            "Done stage 1 of 2\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 23s 23s/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 24s 24s/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 27s 27s/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 26s 26s/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 10000 images.\n",
            "Done stage 2 of 2\n",
            "FID(x_test, x_train) = 2.6792390024659936\n"
          ]
        }
      ],
      "source": [
        "# Compute the FID between the Test set and (the first 10k images of) Train set (should be low)\n",
        "train_fid = get_fid(x_test, x_train[:10_000])\n",
        "\n",
        "# Print out the results\n",
        "print(f\"FID(x_test, x_train) = {train_fid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onQ7QgToTaz9"
      },
      "source": [
        "# Good work!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8vay_urN-3Q",
        "outputId": "6f101e09-776c-4b29-e9c5-e773e7a0ef9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12K\tact_mu.npy\n",
            "33M\tact_sigma.npy\n",
            "55M\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras \n",
        "from keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, Input, LeakyReLU, MaxPooling2D, ReLU, Rescaling, Reshape\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "ggtSpoZyylbX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[3,:,:,0])\n",
        "plt.gray()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "AwOP1L-eno_O",
        "outputId": "bf171409-9397-491d-da2b-074919ea5113"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorDistribution(object):\n",
        "  # source: https://aylien.com/blog/introduction-generative-adversarial-networks-code-tensorflow\n",
        "  \n",
        "  def __init__(self, range):\n",
        "    self.range = range\n",
        "\n",
        "  def sample(self, N):\n",
        "    return np.linspace(-self.range, self.range, N) + np.random.random(N) * 0.01"
      ],
      "metadata": {
        "id": "yILRaKwyJSgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "Oe0GZKdHbpk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator_model(input_shape=(100,), output_shape=(32,32)):\n",
        "  \"\"\"\n",
        "  return the model of the generator\n",
        "  parameters:\n",
        "  output_shape is a tuple containing two values\n",
        "  \"\"\"\n",
        "  x = Input(shape=input_shape)\n",
        "\n",
        "  u1 = output_shape[0]//16\n",
        "  h1 = 128\n",
        "  dense = Dense(u1*u1*h1)(x)\n",
        "  h1 = h1*4\n",
        "  dense = Dense(u1*u1*h1)(dense)\n",
        "  norm = BatchNormalization()(dense)\n",
        "  layer = LeakyReLU()(norm)\n",
        "  layer = Reshape((u1, u1, h1))(layer)\n",
        "\n",
        "  for i in range(4):\n",
        "    h1 = h1//2\n",
        "    strides = 1\n",
        "    for i in range(2):\n",
        "      layer = Conv2DTranspose(h1, 3, strides, padding='same')(layer)\n",
        "      layer = BatchNormalization()(layer)\n",
        "      layer = LeakyReLU()(layer)\n",
        "      strides = strides * 2\n",
        "\n",
        "  # for i in range(3):\n",
        "  #   h1 = h1//2\n",
        "  #   u2 = u1*2\n",
        "  #   layer = Conv2DTranspose(h1, 3, 2, padding='same')(layer)\n",
        "\n",
        "  #   for i in range(2):\n",
        "  #     layer = Conv2D(h1, 3, 1, padding='same', activation='relu')(layer)\n",
        "\n",
        "  y = Conv2DTranspose(1,1,1, padding='same', activation='sigmoid')(layer)\n",
        "\n",
        "  model = Model(x, y)\n",
        "  print(model.summary())\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "bnBTklQnEiBJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = get_generator_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTCZST6j498C",
        "outputId": "29d53130-bfcc-4fc3-91d0-905aabff9f44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               51712     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              1050624   \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 2048)             8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 2048)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 2, 2, 256)        1179904   \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 4, 4, 256)        590080    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 4, 4, 128)        295040    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 8, 8, 128)        147584    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 8, 8, 64)         73792     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 16, 16, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 16, 16, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 16, 16, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 32, 32, 32)       9248      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 32, 32, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 32, 32, 1)        33        \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,465,441\n",
            "Trainable params: 3,459,425\n",
            "Non-trainable params: 6,016\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image generated without training\n",
        "noise = tf.random.normal([10, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "print(generated_image.shape)\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
        "plt.show()\n",
        "print(generated_image[0, :, 10, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "FizgEja5oc8d",
        "outputId": "c38e81d2-a8dc-4a52-c0e7-5a78e37a5468"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 32, 32, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[0.50003445 0.50009626 0.5000688  0.50005203 0.5001103  0.5001222\n",
            " 0.5000418  0.50016975 0.5000751  0.50016016 0.500352   0.50001633\n",
            " 0.50025654 0.5001752  0.50015295 0.50018764 0.50036925 0.5001323\n",
            " 0.50027674 0.50004464 0.5005433  0.50015956 0.5002259  0.5002041\n",
            " 0.5002976  0.50012773 0.5002388  0.49996048 0.50016886 0.50020117\n",
            " 0.50025415 0.50001556], shape=(32,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "RZKXUpgkbvjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_model(input_shape=(32,32,1)):\n",
        "  x = Input(shape=(input_shape))\n",
        "  # layer = Rescaling(1./255)(x)\n",
        "  # layer = Reshape((1,32,32))(x)\n",
        "  \n",
        "  d = input_shape[0]\n",
        "  h1 = 32\n",
        "  # layer = Conv2D(h1, 3, padding='same', activation='relu', data_format='channels_first')(layer)\n",
        "  layer = Conv2D(h1, 3, padding='same')(x)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  \n",
        "  for i in range(4):\n",
        "    layer = Conv2D(h1, 3, padding='same')(layer)\n",
        "    layer = LeakyReLU()(layer)\n",
        "    layer = Conv2D(h1, 3, padding='same')(layer)\n",
        "    layer = LeakyReLU()(layer)\n",
        "    \n",
        "    #layer = Reshape((d,d,h1))(layer)\n",
        "    layer = MaxPooling2D((2,2))(layer)\n",
        "    h1 = h1*2\n",
        "    d = d//2\n",
        "  \n",
        "  layer = Dropout(.2)(layer)\n",
        "  layer = Flatten()(layer)\n",
        "  layer = Dense(h1//2)(layer)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  layer = Dense(h1//8)(layer)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  \n",
        "  y = Dense(1, activation='sigmoid')(layer)\n",
        "\n",
        "  model = Model(x, y)\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "metadata": {
        "id": "4X5pMsEJ_y6C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = get_discriminator_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J33ghwEAgzCA",
        "outputId": "f66e7455-5931-4731-c7d8-c13a659cbfbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,459,841\n",
            "Trainable params: 1,459,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function and optimizers"
      ],
      "metadata": {
        "id": "hZ1U4Fz7kPL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir training_checkpoints"
      ],
      "metadata": {
        "id": "aGQQTr-LkHbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ec4e59-4894-4807-e3f1-f70270ebc090"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äòtraining_checkpoints‚Äô: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ],
      "metadata": {
        "id": "cn5ptbkWjy_5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n"
      ],
      "metadata": {
        "id": "_8NF1mXLkLlE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "LwnRSdwdkc1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "EPOCHS = 300\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(f\"{len(train_dataset)}\")\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
      ],
      "metadata": {
        "id": "4wR28yNLkgFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42aea255-0202-4309-dff4-beb66cccf1a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "noise = None\n",
        "generated_images = None\n",
        "real_output = None\n",
        "fake_output = None\n",
        "gen_loss = None\n",
        "disc_loss = None\n",
        "gradients_of_generator = None\n",
        "gradients_of_discriminator = None\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  global noise, generated_image, real_output, fake_output, gen_loss, disc_loss, gradients_of_generator, gradients_of_discriminator\n",
        "\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    # print(f\"generated images shape: {generated_images.shape}\")\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "metadata": {
        "id": "ebkSSrMAlAij"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      # print(f\"image batch shape: {image_batch.shape}\")\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    # display.clear_output(wait=True)\n",
        "    # generate_and_save_images(generator,epoch + 1,seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  # display.clear_output(wait=True)\n",
        "  # generate_and_save_images(generator,epochs,seed)\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "lr9ex2qZlEMx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTBxIjfemc7M",
        "outputId": "b6fd96b2-79ee-4931-bb20-a3f0ea9639b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 34.63331079483032 sec\n",
            "Time for epoch 2 is 29.880945920944214 sec\n",
            "Time for epoch 3 is 29.63079285621643 sec\n",
            "Time for epoch 4 is 30.061920404434204 sec\n",
            "Time for epoch 5 is 29.96461319923401 sec\n",
            "Time for epoch 6 is 29.887736082077026 sec\n",
            "Time for epoch 7 is 29.94058060646057 sec\n",
            "Time for epoch 8 is 29.97895646095276 sec\n",
            "Time for epoch 9 is 30.019946336746216 sec\n",
            "Time for epoch 10 is 30.039243936538696 sec\n",
            "Time for epoch 11 is 30.03159785270691 sec\n",
            "Time for epoch 12 is 30.055710792541504 sec\n",
            "Time for epoch 13 is 30.028213500976562 sec\n",
            "Time for epoch 14 is 30.048688173294067 sec\n",
            "Time for epoch 15 is 30.55961585044861 sec\n",
            "Time for epoch 16 is 30.003493070602417 sec\n",
            "Time for epoch 17 is 29.970415592193604 sec\n",
            "Time for epoch 18 is 30.00926661491394 sec\n",
            "Time for epoch 19 is 29.923224925994873 sec\n",
            "Time for epoch 20 is 29.91256022453308 sec\n",
            "Time for epoch 21 is 29.930907726287842 sec\n",
            "Time for epoch 22 is 29.91093420982361 sec\n",
            "Time for epoch 23 is 29.8715603351593 sec\n",
            "Time for epoch 24 is 29.837865591049194 sec\n",
            "Time for epoch 25 is 29.89092755317688 sec\n",
            "Time for epoch 26 is 29.882742881774902 sec\n",
            "Time for epoch 27 is 29.85355305671692 sec\n",
            "Time for epoch 28 is 29.901018142700195 sec\n",
            "Time for epoch 29 is 29.928165197372437 sec\n",
            "Time for epoch 30 is 30.272565126419067 sec\n",
            "Time for epoch 31 is 29.792889833450317 sec\n",
            "Time for epoch 32 is 29.905564546585083 sec\n",
            "Time for epoch 33 is 29.839466094970703 sec\n",
            "Time for epoch 34 is 29.73739194869995 sec\n",
            "Time for epoch 35 is 29.73336911201477 sec\n",
            "Time for epoch 36 is 29.805015087127686 sec\n",
            "Time for epoch 37 is 29.851457118988037 sec\n",
            "Time for epoch 38 is 29.763126134872437 sec\n",
            "Time for epoch 39 is 29.671971321105957 sec\n",
            "Time for epoch 40 is 29.702107429504395 sec\n",
            "Time for epoch 41 is 29.772770404815674 sec\n",
            "Time for epoch 42 is 29.750836849212646 sec\n",
            "Time for epoch 43 is 29.79848885536194 sec\n",
            "Time for epoch 44 is 29.7283616065979 sec\n",
            "Time for epoch 45 is 30.085942029953003 sec\n",
            "Time for epoch 46 is 29.6944260597229 sec\n",
            "Time for epoch 47 is 29.719478368759155 sec\n",
            "Time for epoch 48 is 29.68651270866394 sec\n",
            "Time for epoch 49 is 29.776662349700928 sec\n",
            "Time for epoch 50 is 29.75169062614441 sec\n",
            "Time for epoch 51 is 29.74640154838562 sec\n",
            "Time for epoch 52 is 29.740169048309326 sec\n",
            "Time for epoch 53 is 29.726943492889404 sec\n",
            "Time for epoch 54 is 29.71785283088684 sec\n",
            "Time for epoch 55 is 29.75602698326111 sec\n",
            "Time for epoch 56 is 29.7542085647583 sec\n",
            "Time for epoch 57 is 29.657959938049316 sec\n",
            "Time for epoch 58 is 29.639065265655518 sec\n",
            "Time for epoch 59 is 29.683613538742065 sec\n",
            "Time for epoch 60 is 30.02556562423706 sec\n",
            "Time for epoch 61 is 29.610043048858643 sec\n",
            "Time for epoch 62 is 29.71744990348816 sec\n",
            "Time for epoch 63 is 29.704475164413452 sec\n",
            "Time for epoch 64 is 29.668195724487305 sec\n",
            "Time for epoch 65 is 29.625291347503662 sec\n",
            "Time for epoch 66 is 29.669500589370728 sec\n",
            "Time for epoch 67 is 29.647125959396362 sec\n",
            "Time for epoch 68 is 29.700481176376343 sec\n",
            "Time for epoch 69 is 29.65893793106079 sec\n",
            "Time for epoch 70 is 29.620507955551147 sec\n",
            "Time for epoch 71 is 29.676096439361572 sec\n",
            "Time for epoch 72 is 29.66228151321411 sec\n",
            "Time for epoch 73 is 29.63171410560608 sec\n",
            "Time for epoch 74 is 29.647746324539185 sec\n",
            "Time for epoch 75 is 30.089719772338867 sec\n",
            "Time for epoch 76 is 29.641213417053223 sec\n",
            "Time for epoch 77 is 29.667683362960815 sec\n",
            "Time for epoch 78 is 29.640079021453857 sec\n",
            "Time for epoch 79 is 29.593525648117065 sec\n",
            "Time for epoch 80 is 29.567701816558838 sec\n",
            "Time for epoch 81 is 29.574216604232788 sec\n",
            "Time for epoch 82 is 29.59808325767517 sec\n",
            "Time for epoch 83 is 29.59762477874756 sec\n",
            "Time for epoch 84 is 29.572123765945435 sec\n",
            "Time for epoch 85 is 29.572720527648926 sec\n",
            "Time for epoch 86 is 29.57378578186035 sec\n",
            "Time for epoch 87 is 29.629374027252197 sec\n",
            "Time for epoch 88 is 29.60079288482666 sec\n",
            "Time for epoch 89 is 29.61872911453247 sec\n",
            "Time for epoch 90 is 30.00807237625122 sec\n",
            "Time for epoch 91 is 29.547654390335083 sec\n",
            "Time for epoch 92 is 29.588780164718628 sec\n",
            "Time for epoch 93 is 29.64744997024536 sec\n",
            "Time for epoch 94 is 29.64119815826416 sec\n",
            "Time for epoch 95 is 29.64077115058899 sec\n",
            "Time for epoch 96 is 29.63819146156311 sec\n",
            "Time for epoch 97 is 29.666211366653442 sec\n",
            "Time for epoch 98 is 29.647626638412476 sec\n",
            "Time for epoch 99 is 29.580312490463257 sec\n",
            "Time for epoch 100 is 29.533626556396484 sec\n",
            "Time for epoch 101 is 29.552903413772583 sec\n",
            "Time for epoch 102 is 29.56416916847229 sec\n",
            "Time for epoch 103 is 29.558911323547363 sec\n",
            "Time for epoch 104 is 29.52076482772827 sec\n",
            "Time for epoch 105 is 29.833858489990234 sec\n",
            "Time for epoch 106 is 29.485341548919678 sec\n",
            "Time for epoch 107 is 29.621219158172607 sec\n",
            "Time for epoch 108 is 29.58436894416809 sec\n",
            "Time for epoch 109 is 29.590348958969116 sec\n",
            "Time for epoch 110 is 29.575411319732666 sec\n",
            "Time for epoch 111 is 29.548052310943604 sec\n",
            "Time for epoch 112 is 29.54261326789856 sec\n",
            "Time for epoch 113 is 29.53718328475952 sec\n",
            "Time for epoch 114 is 29.56766676902771 sec\n",
            "Time for epoch 115 is 29.513439893722534 sec\n",
            "Time for epoch 116 is 29.552269458770752 sec\n",
            "Time for epoch 117 is 29.564562559127808 sec\n",
            "Time for epoch 118 is 29.570220470428467 sec\n",
            "Time for epoch 119 is 29.587775230407715 sec\n",
            "Time for epoch 120 is 29.915522575378418 sec\n",
            "Time for epoch 121 is 29.497954845428467 sec\n",
            "Time for epoch 122 is 29.527055978775024 sec\n",
            "Time for epoch 123 is 29.561816453933716 sec\n",
            "Time for epoch 124 is 29.570300102233887 sec\n",
            "Time for epoch 125 is 29.544439554214478 sec\n",
            "Time for epoch 126 is 29.551146745681763 sec\n",
            "Time for epoch 127 is 29.552300214767456 sec\n",
            "Time for epoch 128 is 29.570290565490723 sec\n",
            "Time for epoch 129 is 29.57121443748474 sec\n",
            "Time for epoch 130 is 29.54635739326477 sec\n",
            "Time for epoch 131 is 29.558266401290894 sec\n",
            "Time for epoch 132 is 29.584267616271973 sec\n",
            "Time for epoch 133 is 29.584837913513184 sec\n",
            "Time for epoch 134 is 29.615780115127563 sec\n",
            "Time for epoch 135 is 29.91996932029724 sec\n",
            "Time for epoch 136 is 29.548086881637573 sec\n",
            "Time for epoch 137 is 29.609830379486084 sec\n",
            "Time for epoch 138 is 29.608437538146973 sec\n",
            "Time for epoch 139 is 29.614471197128296 sec\n",
            "Time for epoch 140 is 29.60279083251953 sec\n",
            "Time for epoch 141 is 29.619374990463257 sec\n",
            "Time for epoch 142 is 29.66890573501587 sec\n",
            "Time for epoch 143 is 29.64901065826416 sec\n",
            "Time for epoch 144 is 29.711214780807495 sec\n",
            "Time for epoch 145 is 29.67820167541504 sec\n",
            "Time for epoch 146 is 29.657906770706177 sec\n",
            "Time for epoch 147 is 29.67883014678955 sec\n",
            "Time for epoch 148 is 29.668052434921265 sec\n",
            "Time for epoch 149 is 29.683995246887207 sec\n",
            "Time for epoch 150 is 30.01785373687744 sec\n",
            "Time for epoch 151 is 29.58400011062622 sec\n",
            "Time for epoch 152 is 29.64211106300354 sec\n",
            "Time for epoch 153 is 29.656270027160645 sec\n",
            "Time for epoch 154 is 29.643388748168945 sec\n",
            "Time for epoch 155 is 29.630829572677612 sec\n",
            "Time for epoch 156 is 29.678113222122192 sec\n",
            "Time for epoch 157 is 29.712124824523926 sec\n",
            "Time for epoch 158 is 29.665446043014526 sec\n",
            "Time for epoch 159 is 29.64191246032715 sec\n",
            "Time for epoch 160 is 29.627107620239258 sec\n",
            "Time for epoch 161 is 29.588690280914307 sec\n",
            "Time for epoch 162 is 29.586289405822754 sec\n",
            "Time for epoch 163 is 29.580244541168213 sec\n",
            "Time for epoch 164 is 29.551342964172363 sec\n",
            "Time for epoch 165 is 29.91236162185669 sec\n",
            "Time for epoch 166 is 29.527039051055908 sec\n",
            "Time for epoch 167 is 29.549078702926636 sec\n",
            "Time for epoch 168 is 29.54676055908203 sec\n",
            "Time for epoch 169 is 29.588305234909058 sec\n",
            "Time for epoch 170 is 29.64244031906128 sec\n",
            "Time for epoch 171 is 29.57071852684021 sec\n",
            "Time for epoch 172 is 29.596456050872803 sec\n",
            "Time for epoch 173 is 29.639870643615723 sec\n",
            "Time for epoch 174 is 29.622044563293457 sec\n",
            "Time for epoch 175 is 29.60479211807251 sec\n",
            "Time for epoch 176 is 29.606276750564575 sec\n",
            "Time for epoch 177 is 29.6112322807312 sec\n",
            "Time for epoch 178 is 29.609869956970215 sec\n",
            "Time for epoch 179 is 29.58513069152832 sec\n",
            "Time for epoch 180 is 29.9388689994812 sec\n",
            "Time for epoch 181 is 29.535004377365112 sec\n",
            "Time for epoch 182 is 29.582724809646606 sec\n",
            "Time for epoch 183 is 29.592926502227783 sec\n",
            "Time for epoch 184 is 29.54056167602539 sec\n",
            "Time for epoch 185 is 29.57285499572754 sec\n",
            "Time for epoch 186 is 29.547032833099365 sec\n",
            "Time for epoch 187 is 29.59827756881714 sec\n",
            "Time for epoch 188 is 29.565377473831177 sec\n",
            "Time for epoch 189 is 29.56580138206482 sec\n",
            "Time for epoch 190 is 29.573944091796875 sec\n",
            "Time for epoch 191 is 29.5709707736969 sec\n",
            "Time for epoch 192 is 29.58171582221985 sec\n",
            "Time for epoch 193 is 29.572279453277588 sec\n",
            "Time for epoch 194 is 29.602402448654175 sec\n",
            "Time for epoch 195 is 30.019327402114868 sec\n",
            "Time for epoch 196 is 29.55103039741516 sec\n",
            "Time for epoch 197 is 29.58586621284485 sec\n",
            "Time for epoch 198 is 29.594963312149048 sec\n",
            "Time for epoch 199 is 29.593602657318115 sec\n",
            "Time for epoch 200 is 29.599281311035156 sec\n",
            "Time for epoch 201 is 29.59049105644226 sec\n",
            "Time for epoch 202 is 29.583516836166382 sec\n",
            "Time for epoch 203 is 29.609833478927612 sec\n",
            "Time for epoch 204 is 29.617806673049927 sec\n",
            "Time for epoch 205 is 29.618823289871216 sec\n",
            "Time for epoch 206 is 29.656208992004395 sec\n",
            "Time for epoch 207 is 29.539623260498047 sec\n",
            "Time for epoch 208 is 29.571216583251953 sec\n",
            "Time for epoch 209 is 29.588595628738403 sec\n",
            "Time for epoch 210 is 29.904419660568237 sec\n",
            "Time for epoch 211 is 29.534781217575073 sec\n",
            "Time for epoch 212 is 29.617411136627197 sec\n",
            "Time for epoch 213 is 29.59526562690735 sec\n",
            "Time for epoch 214 is 29.615508317947388 sec\n",
            "Time for epoch 215 is 29.617405891418457 sec\n",
            "Time for epoch 216 is 29.6354558467865 sec\n",
            "Time for epoch 217 is 29.630966424942017 sec\n",
            "Time for epoch 218 is 29.619128942489624 sec\n",
            "Time for epoch 219 is 29.566943645477295 sec\n",
            "Time for epoch 220 is 29.517157316207886 sec\n",
            "Time for epoch 221 is 29.546478271484375 sec\n",
            "Time for epoch 222 is 29.481502056121826 sec\n",
            "Time for epoch 223 is 29.523712158203125 sec\n",
            "Time for epoch 224 is 29.565475463867188 sec\n",
            "Time for epoch 225 is 29.91758131980896 sec\n",
            "Time for epoch 226 is 29.54283618927002 sec\n",
            "Time for epoch 227 is 29.63327646255493 sec\n",
            "Time for epoch 228 is 29.620344400405884 sec\n",
            "Time for epoch 229 is 29.614423513412476 sec\n",
            "Time for epoch 230 is 29.625483989715576 sec\n",
            "Time for epoch 231 is 29.619356393814087 sec\n",
            "Time for epoch 232 is 29.61814045906067 sec\n",
            "Time for epoch 233 is 29.598675966262817 sec\n",
            "Time for epoch 234 is 29.581364154815674 sec\n",
            "Time for epoch 235 is 29.57564067840576 sec\n",
            "Time for epoch 236 is 29.582871675491333 sec\n",
            "Time for epoch 237 is 29.601770877838135 sec\n",
            "Time for epoch 238 is 29.609458208084106 sec\n",
            "Time for epoch 239 is 29.62602424621582 sec\n",
            "Time for epoch 240 is 30.047882795333862 sec\n",
            "Time for epoch 241 is 29.530943870544434 sec\n",
            "Time for epoch 242 is 29.598700761795044 sec\n",
            "Time for epoch 243 is 29.59854793548584 sec\n",
            "Time for epoch 244 is 29.5645854473114 sec\n",
            "Time for epoch 245 is 29.564372301101685 sec\n",
            "Time for epoch 246 is 29.572946548461914 sec\n",
            "Time for epoch 247 is 29.55629253387451 sec\n",
            "Time for epoch 248 is 29.543273210525513 sec\n",
            "Time for epoch 249 is 29.551472425460815 sec\n",
            "Time for epoch 250 is 29.550816774368286 sec\n",
            "Time for epoch 251 is 29.546692371368408 sec\n",
            "Time for epoch 252 is 29.566638469696045 sec\n",
            "Time for epoch 253 is 29.530681133270264 sec\n",
            "Time for epoch 254 is 29.56996440887451 sec\n",
            "Time for epoch 255 is 29.92920684814453 sec\n",
            "Time for epoch 256 is 29.49798035621643 sec\n",
            "Time for epoch 257 is 29.514125108718872 sec\n",
            "Time for epoch 258 is 29.534857273101807 sec\n",
            "Time for epoch 259 is 29.562159061431885 sec\n",
            "Time for epoch 260 is 29.540961265563965 sec\n",
            "Time for epoch 261 is 29.544914484024048 sec\n",
            "Time for epoch 262 is 29.53097653388977 sec\n",
            "Time for epoch 263 is 29.53147029876709 sec\n",
            "Time for epoch 264 is 29.513177156448364 sec\n",
            "Time for epoch 265 is 29.483094930648804 sec\n",
            "Time for epoch 266 is 29.4897141456604 sec\n",
            "Time for epoch 267 is 29.501075267791748 sec\n",
            "Time for epoch 268 is 29.49524450302124 sec\n",
            "Time for epoch 269 is 29.525492191314697 sec\n",
            "Time for epoch 270 is 29.84854483604431 sec\n",
            "Time for epoch 271 is 29.45829677581787 sec\n",
            "Time for epoch 272 is 29.513484716415405 sec\n",
            "Time for epoch 273 is 29.53190803527832 sec\n",
            "Time for epoch 274 is 29.53525948524475 sec\n",
            "Time for epoch 275 is 29.57552433013916 sec\n",
            "Time for epoch 276 is 29.568760633468628 sec\n",
            "Time for epoch 277 is 29.572521686553955 sec\n",
            "Time for epoch 278 is 29.582242250442505 sec\n",
            "Time for epoch 279 is 29.593414068222046 sec\n",
            "Time for epoch 280 is 29.605997800827026 sec\n",
            "Time for epoch 281 is 29.593868255615234 sec\n",
            "Time for epoch 282 is 29.590880632400513 sec\n",
            "Time for epoch 283 is 29.59979486465454 sec\n",
            "Time for epoch 284 is 29.568589687347412 sec\n",
            "Time for epoch 285 is 29.948484897613525 sec\n",
            "Time for epoch 286 is 29.535121202468872 sec\n",
            "Time for epoch 287 is 29.560463428497314 sec\n",
            "Time for epoch 288 is 29.56831455230713 sec\n",
            "Time for epoch 289 is 29.58491039276123 sec\n",
            "Time for epoch 290 is 29.594786167144775 sec\n",
            "Time for epoch 291 is 29.587011337280273 sec\n",
            "Time for epoch 292 is 29.59719491004944 sec\n",
            "Time for epoch 293 is 29.553924798965454 sec\n",
            "Time for epoch 294 is 29.587626457214355 sec\n",
            "Time for epoch 295 is 29.567994356155396 sec\n",
            "Time for epoch 296 is 29.577446222305298 sec\n",
            "Time for epoch 297 is 29.588308811187744 sec\n",
            "Time for epoch 298 is 29.585145711898804 sec\n",
            "Time for epoch 299 is 29.611241340637207 sec\n",
            "Time for epoch 300 is 29.926151990890503 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "2biPUQ_hy1FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([16, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "print(\"Generated images\")\n",
        "\n",
        "# Create a figure with 4x4 subplots\n",
        "fig, axes = plt.subplots(4, 4)\n",
        "\n",
        "# Loop over the images and axes and plot them\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(generated_image[i])\n",
        "    ax.axis('off')\n",
        "    \n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "# Show the figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "mGWUtnWwlOFT",
        "outputId": "cf4e8191-dcb4-4014-9ef3-8252f5b361a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([10000, 32, 32, 1])\n",
        "# Compute the FID between the noise and 10k generated images\n",
        "noise_fid = get_fid(x_test, noise)\n",
        "\n",
        "# Print out the results\n",
        "print(f\"FID(x_test, noise) = {noise_fid}\")"
      ],
      "metadata": {
        "id": "u3FbaumuolIT",
        "outputId": "1d594be6-d2e0-4999-892e-3b084dc08338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FID for (10000, 32, 32, 1) dimensional images\n",
            "Done stage 1 of 2\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 0s 364ms/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 10000 images.\n",
            "Done stage 2 of 2\n",
            "FID(x_test, noise) = 400.9337189566532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([10000, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# Compute the FID between the Test set and 10k generated images\n",
        "generated_images_fid = get_fid(x_test, generated_image)\n",
        "\n",
        "# Print out the results\n",
        "print(f\"FID(x_test, generated_images) = {generated_images_fid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSQ8gXIonRpn",
        "outputId": "27338d80-0fb5-4542-b402-3ee3f5bff245"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FID for (10000, 32, 32, 1) dimensional images\n",
            "Done stage 1 of 2\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 0s 201ms/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 0s 152ms/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 1s 634ms/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "Processed 10000 images.\n",
            "Done stage 2 of 2\n",
            "FID(x_test, generated_images) = 262.64440444735874\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.11 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2db16da740494d35c7f3749582ea0fec8725a5f0d9e976cf583dd1041e9a5f0f"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}