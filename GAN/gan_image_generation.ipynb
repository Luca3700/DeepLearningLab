{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSWSrJ-iTazX"
      },
      "source": [
        "# Generating Images with Generative Adversarial Networks (GANs)\n",
        "\n",
        "The purpose of the project is to test the ability of Generative Adversial Networks (GANs) in generating realistic-looking images. \n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset used will be FashionMNIST. It contains low resolution ($28 \\times 28$) grey-scale images representing different kind of clothes. The dataset is available on keras and accessable in $\\texttt{tf.keras.datasets.fashion\\_mnist}$. Note that the pixel values for the images are initially in the interval $[0, 255]$. It is required to normalize them since all of the algorithm we will use require them to be in that format. To be fair, you will find the dataset already normalized, do not modify that part of the code.\n",
        "\n",
        "## Metrics\n",
        "\n",
        "Measuring the quality of newly generated images is a non-trivial task. Indeed, there is no label associated to each image, and thus it is impossible to measure the quality image-by-image. For that reason, common metrics uses statistical consideration on a generated dataset to test how well the network recovered the statistics of the original data. One of the most common is the Fr√©chet Inception Distance (FID). The idea of FID is that in a realistic-looking dataset of images, the statistics of the activation of the last hidden layer in a well-trained classificator should be similar to that of a dataset containing real images. Specifically, regarding FID, the Inception-v3 network is used as a classificator. A real dataset $\\mathbb{D}_r$ and a generated dataset $\\mathbb{D}_g$ are processed by the network, and the activation of the last hidden layer has mean and variance $(\\mu_r, \\Sigma_r)$, $(\\mu_g, \\Sigma_g)$ respectively. Then, FID is computed as:\n",
        "\n",
        "$$\n",
        "    FID(\\mathbb{D}_r, \\mathbb{D}_g) = || \\mu_r - \\mu_g ||^2 + Tr(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r \\ast \\Sigma_g)^{\\frac{1}{2}}) \n",
        "$$\n",
        "\n",
        "A Python implementation of FID can be found in the file $\\texttt{fid.py}$ that you find attached on Virtuale. Its usage is very simple, just generate $10k$ fake images with your GAN, and with the command $\\texttt{fid.get\\_fid(x\\_test, x\\_gen)}$, where $\\texttt{x\\_test}$ is the test set, containing $10k$ real images, you get the value for the FID of your network. Remember that, when passed through that function, $\\texttt{x\\_gen}$ **must** be a dataset of $10k$ images, in the interval $[0, 1]$. The number of $10k$ images is fundamental, since the value of FID strongly depends on the number of input images.\n",
        "\n",
        "## Limitations\n",
        "\n",
        "You are required to implement a vanilla Generative Adversarial Network (GAN), not a variant of it (e.g. PixelGAN, CycleGAN, ... are **not** accepted). The maximum number of parameters is *15 million*, and every pre-trained network can be used as an add-on (the number of parameters for pre-trained network does not count). Clearly, only the training set can be used to train the network, no additional images (Data Augmentation is ok)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aaubgTXbTazn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceos7zgTTazs"
      },
      "source": [
        "The images are normalized in $[0, 1]$. For simplicity, images are padded to have dimension $32 \\times 32$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es5LDnq0Tazv",
        "outputId": "2e8cf54b-6ee3-4678-f491-f3608421a372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Training shape: (60000, 32, 32, 1), Training pixel values: (0.0, 1.0)\n",
            "Test shape: (10000, 32, 32, 1), Test pixel values: (0.0, 1.0)\n"
          ]
        }
      ],
      "source": [
        "# Load the data. Note that the labels y_train and y_test are not loaded since not required.\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and pad the datasets\n",
        "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)))\n",
        "x_train = np.reshape(x_train, x_train.shape + (1, ))\n",
        "x_train = x_train / 255.\n",
        "\n",
        "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)))\n",
        "x_test = np.reshape(x_test, x_test.shape + (1, ))\n",
        "x_test = x_test / 255.\n",
        "\n",
        "print(f\"Training shape: {x_train.shape}, Training pixel values: {x_train.min(), x_train.max()}\")\n",
        "print(f\"Test shape: {x_test.shape}, Test pixel values: {x_test.min(), x_test.max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRRpm4TkTazy"
      },
      "source": [
        "Now, we import the functions for the computation of the FID, and we test that FID(x_train, x_test) is low.\n",
        "\n",
        "_Note: Computing the FID function requires some minutes. Consequently, it is suggested to comment this cell after you tested once, to reduce the execution time of the notebook. To speed-up the process, after a first use, the function will generate a file containing the value of the activations of the test set, so that it does not have to compute it again every time._ \n",
        "\n",
        "**Remember that, when you use the FID function, the first input MUST be the test set, while the second will be the generated images set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dPZU1oiTaz1",
        "outputId": "8c414df9-8bb1-4219-b8da-77db5cc71528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Do not modify this code. This is just for utilities.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# prepare the inception v3 model\n",
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3), weights='imagenet')\n",
        "\n",
        "def get_inception_activations(inps, batch_size=100):\n",
        "    \"\"\"\n",
        "    Compute the activation for the model Inception v3 for a given input 'inps'.\n",
        "\n",
        "    Note: inps is assumed to be normalized in [0, 1].\n",
        "    \"\"\"\n",
        "    n_batches = inps.shape[0] // batch_size\n",
        "\n",
        "    act = np.zeros([inps.shape[0], 2048], dtype=np.float32)\n",
        "    for i in range(n_batches):\n",
        "        # Load a batch of data\n",
        "        inp = inps[i * batch_size:(i + 1) * batch_size]\n",
        "\n",
        "        # Resize each image to match the input shape of Inception v3\n",
        "        inpr = tf.image.resize(inp, (299, 299))\n",
        "\n",
        "        # Resize images in the interval [-1, 1], given that inpr is in [0, 1].\n",
        "        inpr = inpr * 2 - 1 \n",
        "\n",
        "        # Predict the activation\n",
        "        act[i * batch_size:(i + 1) * batch_size] = model.predict(inpr, steps=1)\n",
        "\n",
        "        print(f\"Processed {str((i + 1) * batch_size)} images.\")\n",
        "    return act\n",
        "\n",
        "\n",
        "def get_fid(images1, images2):\n",
        "    \"\"\"\n",
        "    Compute the FID between two sets of images.\n",
        "\n",
        "    Note: it can take several minutes.\n",
        "    \"\"\"\n",
        "    from scipy.linalg import sqrtm\n",
        "\n",
        "    shape = np.shape(images1)[1]\n",
        "    print(\"Computing FID for {} dimensional images\".format(images1.shape))\n",
        "\n",
        "    # Inception v3 requires the input to have 3 channel. If this is not the\n",
        "    # case, just copy the same channel three times.\n",
        "    if images1.shape[-1] == 1:\n",
        "        images1 = np.concatenate([images1, images1, images1], axis=-1)\n",
        "        images2 = np.concatenate([images2, images2, images2], axis=-1)\n",
        "\n",
        "    # activation for true images is always the same: we just compute it once\n",
        "    if os.path.exists(\"act_mu.npy\"):\n",
        "        mu1 = np.load(\"act_mu.npy\")\n",
        "        sigma1 = np.load(\"act_sigma.npy\")\n",
        "    else:\n",
        "        act1 = get_inception_activations(images1)\n",
        "        mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "        np.save(\"act_mu.npy\", mu1)\n",
        "        np.save(\"act_sigma.npy\", sigma1)\n",
        "    print('Done stage 1 of 2')\n",
        "\n",
        "    act2 = get_inception_activations(images2)\n",
        "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "    print('Done stage 2 of 2')\n",
        "\n",
        "    # calculate sum squared difference between means\n",
        "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
        "\n",
        "    # compute sqrt of product between cov\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "    # check and correct imaginary numbers from sqrt\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    # calculate score\n",
        "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    return fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OogQ0Wt3Taz7",
        "outputId": "9a8442b5-06db-45c7-99f8-60fcdb6874d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FID for (10000, 32, 32, 1) dimensional images\n",
            "1/1 [==============================] - 23s 23s/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 10000 images.\n",
            "Done stage 1 of 2\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 23s 23s/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 29s 29s/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 24s 24s/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 27s 27s/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 26s 26s/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 25s 25s/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 21s 21s/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "Processed 10000 images.\n",
            "Done stage 2 of 2\n",
            "FID(x_test, x_train) = 2.6792390024659936\n"
          ]
        }
      ],
      "source": [
        "# Compute the FID between the Test set and (the first 10k images of) Train set (should be low)\n",
        "train_fid = get_fid(x_test, x_train[:10_000])\n",
        "\n",
        "# Print out the results\n",
        "print(f\"FID(x_test, x_train) = {train_fid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onQ7QgToTaz9"
      },
      "source": [
        "# Good work!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8vay_urN-3Q",
        "outputId": "6f101e09-776c-4b29-e9c5-e773e7a0ef9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12K\tact_mu.npy\n",
            "33M\tact_sigma.npy\n",
            "55M\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras \n",
        "from keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, Input, LeakyReLU, MaxPooling2D, ReLU, Rescaling, Reshape\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "ggtSpoZyylbX"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[3,:,:,0])\n",
        "plt.gray()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "AwOP1L-eno_O",
        "outputId": "bf171409-9397-491d-da2b-074919ea5113"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorDistribution(object):\n",
        "  # source: https://aylien.com/blog/introduction-generative-adversarial-networks-code-tensorflow\n",
        "  \n",
        "  def __init__(self, range):\n",
        "    self.range = range\n",
        "\n",
        "  def sample(self, N):\n",
        "    return np.linspace(-self.range, self.range, N) + np.random.random(N) * 0.01"
      ],
      "metadata": {
        "id": "yILRaKwyJSgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "Oe0GZKdHbpk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator_model(input_shape=(100,), output_shape=(32,32)):\n",
        "  \"\"\"\n",
        "  return the model of the generator\n",
        "  parameters:\n",
        "  output_shape is a tuple containing two values\n",
        "  \"\"\"\n",
        "  x = Input(shape=input_shape)\n",
        "\n",
        "  u1 = output_shape[0]//16\n",
        "  h1 = 128\n",
        "  dense = Dense(u1*u1*h1)(x)\n",
        "  h1 = h1*4\n",
        "  dense = Dense(u1*u1*h1)(dense)\n",
        "  norm = BatchNormalization()(dense)\n",
        "  layer = LeakyReLU()(norm)\n",
        "  layer = Reshape((u1, u1, h1))(layer)\n",
        "\n",
        "  for i in range(4):\n",
        "    h1 = h1//2\n",
        "    strides = 1\n",
        "    for i in range(2):\n",
        "      layer = Conv2DTranspose(h1, 3, strides, padding='same')(layer)\n",
        "      layer = BatchNormalization()(layer)\n",
        "      layer = LeakyReLU()(layer)\n",
        "      strides = strides * 2\n",
        "\n",
        "  # for i in range(3):\n",
        "  #   h1 = h1//2\n",
        "  #   u2 = u1*2\n",
        "  #   layer = Conv2DTranspose(h1, 3, 2, padding='same')(layer)\n",
        "\n",
        "  #   for i in range(2):\n",
        "  #     layer = Conv2D(h1, 3, 1, padding='same', activation='relu')(layer)\n",
        "\n",
        "  y = Conv2DTranspose(1,1,1, padding='same', activation='sigmoid')(layer)\n",
        "\n",
        "  model = Model(x, y)\n",
        "  print(model.summary())\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "bnBTklQnEiBJ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = get_generator_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTCZST6j498C",
        "outputId": "c6aebc39-69fa-4e3b-8933-6e649a34e7f5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 100)]             0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               51712     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2048)              1050624   \n",
            "                                                                 \n",
            " batch_normalization_121 (Ba  (None, 2048)             8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 2048)              0         \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_27 (Conv2D  (None, 2, 2, 256)        1179904   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_122 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_28 (Conv2D  (None, 4, 4, 256)        590080    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_123 (Ba  (None, 4, 4, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_29 (Conv2D  (None, 4, 4, 128)        295040    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_124 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_30 (Conv2D  (None, 8, 8, 128)        147584    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_125 (Ba  (None, 8, 8, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_31 (Conv2D  (None, 8, 8, 64)         73792     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_126 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_32 (Conv2D  (None, 16, 16, 64)       36928     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_127 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_33 (Conv2D  (None, 16, 16, 32)       18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_128 (Ba  (None, 16, 16, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_34 (Conv2D  (None, 32, 32, 32)       9248      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_129 (Ba  (None, 32, 32, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_35 (Conv2D  (None, 32, 32, 1)        33        \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,465,441\n",
            "Trainable params: 3,459,425\n",
            "Non-trainable params: 6,016\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image generated without training\n",
        "noise = tf.random.normal([10, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "print(generated_image.shape)\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
        "plt.show()\n",
        "print(generated_image[0, :, 10, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "FizgEja5oc8d",
        "outputId": "c38e81d2-a8dc-4a52-c0e7-5a78e37a5468"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 32, 32, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[0.50003445 0.50009626 0.5000688  0.50005203 0.5001103  0.5001222\n",
            " 0.5000418  0.50016975 0.5000751  0.50016016 0.500352   0.50001633\n",
            " 0.50025654 0.5001752  0.50015295 0.50018764 0.50036925 0.5001323\n",
            " 0.50027674 0.50004464 0.5005433  0.50015956 0.5002259  0.5002041\n",
            " 0.5002976  0.50012773 0.5002388  0.49996048 0.50016886 0.50020117\n",
            " 0.50025415 0.50001556], shape=(32,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "RZKXUpgkbvjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_model(input_shape=(32,32,1)):\n",
        "  x = Input(shape=(input_shape))\n",
        "  # layer = Rescaling(1./255)(x)\n",
        "  # layer = Reshape((1,32,32))(x)\n",
        "  \n",
        "  d = input_shape[0]\n",
        "  h1 = 32\n",
        "  # layer = Conv2D(h1, 3, padding='same', activation='relu', data_format='channels_first')(layer)\n",
        "  layer = Conv2D(h1, 3, padding='same')(x)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  \n",
        "  for i in range(4):\n",
        "    layer = Conv2D(h1, 3, padding='same')(layer)\n",
        "    layer = LeakyReLU()(layer)\n",
        "    layer = Conv2D(h1, 3, padding='same')(layer)\n",
        "    layer = LeakyReLU()(layer)\n",
        "    \n",
        "    #layer = Reshape((d,d,h1))(layer)\n",
        "    layer = MaxPooling2D((2,2))(layer)\n",
        "    h1 = h1*2\n",
        "    d = d//2\n",
        "  \n",
        "  layer = Dropout(.2)(layer)\n",
        "  layer = Flatten()(layer)\n",
        "  layer = Dense(h1//2)(layer)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  layer = Dense(h1//8)(layer)\n",
        "  layer = LeakyReLU()(layer)\n",
        "  \n",
        "  y = Dense(1, activation='sigmoid')(layer)\n",
        "\n",
        "  model = Model(x, y)\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "metadata": {
        "id": "4X5pMsEJ_y6C"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = get_discriminator_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J33ghwEAgzCA",
        "outputId": "b14a518b-ad76-4e7b-f728-661e7822ecb5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_172 (Conv2D)         (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu_46 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu_47 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_174 (Conv2D)         (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu_48 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_49 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_176 (Conv2D)         (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " leaky_re_lu_50 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_177 (Conv2D)         (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_51 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_178 (Conv2D)         (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_52 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_53 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_180 (Conv2D)         (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " leaky_re_lu_54 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 2, 2, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " leaky_re_lu_55 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " leaky_re_lu_56 (LeakyReLU)  (None, 64)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,459,841\n",
            "Trainable params: 1,459,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function and optimizers"
      ],
      "metadata": {
        "id": "hZ1U4Fz7kPL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir training_checkpoints"
      ],
      "metadata": {
        "id": "aGQQTr-LkHbM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ],
      "metadata": {
        "id": "cn5ptbkWjy_5"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n"
      ],
      "metadata": {
        "id": "_8NF1mXLkLlE"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "LwnRSdwdkc1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(f\"{len(train_dataset)}\")\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
      ],
      "metadata": {
        "id": "4wR28yNLkgFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3399ea6a-83c4-4f05-bef2-ddc0d6a2a47d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "noise = None\n",
        "generated_images = None\n",
        "real_output = None\n",
        "fake_output = None\n",
        "gen_loss = None\n",
        "disc_loss = None\n",
        "gradients_of_generator = None\n",
        "gradients_of_discriminator = None\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  global noise, generated_image, real_output, fake_output, gen_loss, disc_loss, gradients_of_generator, gradients_of_discriminator\n",
        "\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "  # print(f\"images shape: {images.shape}\\nnoise shape: {noise.shape}\")\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    # print(f\"generated images shape: {generated_images.shape}\")\n",
        "\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "metadata": {
        "id": "ebkSSrMAlAij"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      # print(f\"image batch shape: {image_batch.shape}\")\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    # display.clear_output(wait=True)\n",
        "    # generate_and_save_images(generator,epoch + 1,seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    print(f\"gen_loss: {gen_loss}   disc_loss: {disc_loss}\")\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  # display.clear_output(wait=True)\n",
        "  # generate_and_save_images(generator,epochs,seed)\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "lr9ex2qZlEMx"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTBxIjfemc7M",
        "outputId": "c5a7f09d-bdb1-4ff5-b47a-be24ace9b565"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 43.37006735801697 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 2 is 30.05308747291565 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 3 is 30.227323055267334 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 4 is 29.90657687187195 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 5 is 30.08902335166931 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 6 is 30.14944291114807 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 7 is 30.030385494232178 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 8 is 30.06236457824707 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 9 is 29.90696096420288 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 10 is 30.121411561965942 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 11 is 30.144365310668945 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 12 is 30.146254062652588 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 13 is 30.122810125350952 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 14 is 30.0366952419281 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 15 is 30.469372510910034 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 16 is 29.955442667007446 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 17 is 30.026740550994873 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 18 is 29.989959716796875 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 19 is 30.039780855178833 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 20 is 30.049535036087036 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 21 is 30.0797278881073 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 22 is 30.080384016036987 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 23 is 30.03516697883606 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 24 is 29.971263647079468 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 25 is 29.97381043434143 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 26 is 29.936562538146973 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 27 is 30.00484013557434 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 28 is 30.051756381988525 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 29 is 30.056570053100586 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 30 is 30.364993572235107 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 31 is 29.908884286880493 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 32 is 30.036084175109863 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 33 is 29.983795404434204 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 34 is 29.941027641296387 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 35 is 29.92919158935547 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 36 is 29.91499352455139 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 37 is 29.948441743850708 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 38 is 29.91071081161499 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 39 is 29.955731630325317 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 40 is 29.873880863189697 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 41 is 29.849703073501587 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 42 is 29.852909564971924 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 43 is 29.83054780960083 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 44 is 29.796587228775024 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 45 is 30.211517572402954 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 46 is 29.783609628677368 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 47 is 29.86377739906311 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 48 is 29.85045552253723 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 49 is 29.854644060134888 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 50 is 29.83059334754944 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 51 is 29.8006272315979 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 52 is 29.846946716308594 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 53 is 29.853368520736694 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 54 is 29.809330940246582 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 55 is 29.813565731048584 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 56 is 29.82075023651123 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 57 is 29.81016516685486 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 58 is 29.822883367538452 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 59 is 29.791211366653442 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 60 is 30.17337965965271 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 61 is 29.744394779205322 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 62 is 29.767165422439575 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 63 is 29.727678298950195 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 64 is 29.773930311203003 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 65 is 29.745716094970703 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 66 is 29.734911680221558 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 67 is 29.682899951934814 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 68 is 29.727375507354736 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 69 is 29.79448890686035 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 70 is 29.789361715316772 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 71 is 29.814757585525513 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 72 is 29.789039134979248 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 73 is 29.774027585983276 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 74 is 29.772721767425537 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 75 is 30.07625961303711 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 76 is 29.66971778869629 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 77 is 29.741767168045044 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 78 is 29.746822595596313 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 79 is 29.758546590805054 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 80 is 29.76774287223816 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 81 is 29.757935762405396 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 82 is 29.69281530380249 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 83 is 29.699460983276367 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 84 is 29.678803205490112 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 85 is 29.672664642333984 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 86 is 29.8710675239563 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 87 is 29.731029987335205 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 88 is 29.659610271453857 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 89 is 29.74662709236145 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 90 is 30.185554265975952 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 91 is 29.70025062561035 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 92 is 29.7086980342865 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 93 is 29.670443296432495 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 94 is 29.705941438674927 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 95 is 29.781804084777832 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 96 is 29.777328968048096 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 97 is 29.75592565536499 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 98 is 29.756226539611816 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 99 is 29.7387855052948 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "Time for epoch 100 is 29.721441745758057 sec\n",
            "gen_loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)   disc_loss: Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "2biPUQ_hy1FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"generator loss: {gen_loss}\\ndiscriminator loss: {disc_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I-R5KAtkrli",
        "outputId": "0f24c1b5-c0d7-4a14-c769-8a3e700b6ef5"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generator loss: Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "discriminator loss: Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([16, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "print(\"Generated images\")\n",
        "\n",
        "# Create a figure with 4x4 subplots\n",
        "fig, axes = plt.subplots(4, 4)\n",
        "\n",
        "# Loop over the images and axes and plot them\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(generated_image[i])\n",
        "    ax.axis('off')\n",
        "    \n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "# Show the figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "mGWUtnWwlOFT",
        "outputId": "377e9319-38bb-4b53-cb4a-2dbab5f39493"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([10000, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# Compute the FID between the Test set and 10k generated images\n",
        "generated_images_fid = get_fid(x_test, generated_image)\n",
        "\n",
        "# Print out the results\n",
        "print(f\"FID(x_test, generated_images) = {generated_images_fid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSQ8gXIonRpn",
        "outputId": "b850710e-21b8-4137-b4df-960985f549c6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing FID for (10000, 32, 32, 1) dimensional images\n",
            "Done stage 1 of 2\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "Processed 100 images.\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "Processed 200 images.\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "Processed 300 images.\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "Processed 400 images.\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "Processed 500 images.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Processed 600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 800 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 900 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 1000 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 1100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 1200 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 1300 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 1400 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 1500 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 1600 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 1700 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 1800 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 1900 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 2000 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 2100 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 2200 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 2300 images.\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "Processed 2400 images.\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "Processed 2500 images.\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Processed 2600 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 2700 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 2800 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 2900 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3000 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 3100 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 3200 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 3300 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 3400 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 3500 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 3600 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 3700 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 3800 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 3900 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 4000 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 4100 images.\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "Processed 4200 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 4300 images.\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "Processed 4400 images.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "Processed 4500 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 4600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 4700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 4800 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 4900 images.\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "Processed 5000 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 5100 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 5200 images.\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "Processed 5300 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 5400 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 5500 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 5600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 5700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 5800 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 5900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 6000 images.\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "Processed 6100 images.\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "Processed 6200 images.\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Processed 6300 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 6400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 6500 images.\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "Processed 6600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 6700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 6800 images.\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Processed 6900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 7000 images.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Processed 7100 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 7200 images.\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Processed 7300 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 7400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 7500 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 7600 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 7700 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 7800 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 7900 images.\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "Processed 8000 images.\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "Processed 8100 images.\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "Processed 8200 images.\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "Processed 8300 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 8400 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 8500 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 8600 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 8700 images.\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Processed 8800 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 8900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 9000 images.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "Processed 9100 images.\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Processed 9200 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 9300 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 9400 images.\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "Processed 9500 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 9600 images.\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Processed 9700 images.\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Processed 9800 images.\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "Processed 9900 images.\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Processed 10000 images.\n",
            "Done stage 2 of 2\n",
            "FID(x_test, generated_images) = 214.84968326871186\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.11 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2db16da740494d35c7f3749582ea0fec8725a5f0d9e976cf583dd1041e9a5f0f"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}